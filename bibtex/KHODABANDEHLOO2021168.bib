@article{KHODABANDEHLOO2021168,
title = {HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline},
journal = {Future Generation Computer Systems},
volume = {116},
pages = {168-189},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.10.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20330144},
author = {Elham Khodabandehloo and Daniele Riboni and Abbas Alimohammadi},
keywords = {Pervasive healthcare, Explainable artificial intelligence, Cognitive decline, Sensor-based activity recognition},
abstract = {Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system’s predictions are significantly correlated to the person’s actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline.}
}