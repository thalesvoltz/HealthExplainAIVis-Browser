@article{QUELLEC2021102118,
title = {ExplAIn: Explanatory artificial intelligence for diabetic retinopathy diagnosis},
journal = {Medical Image Analysis},
volume = {72},
pages = {102118},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102118},
url = {https://www.sciencedirect.com/science/article/pii/S136184152100164X},
author = {Gwenolé Quellec and Hassan {Al Hajj} and Mathieu Lamard and Pierre-Henri Conze and Pascale Massin and Béatrice Cochener},
keywords = {Explanatory artificial intelligence, Self-supervised learning, Diabetic retinopathy diagnosis},
abstract = {In recent years, Artificial Intelligence (AI) has proven its relevance for medical decision support. However, the “black-box” nature of successful AI algorithms still holds back their wide-spread deployment. In this paper, we describe an eXplanatory Artificial Intelligence (XAI) that reaches the same level of performance as black-box AI, for the task of classifying Diabetic Retinopathy (DR) severity using Color Fundus Photography (CFP). This algorithm, called ExplAIn, learns to segment and categorize lesions in images; the final image-level classification directly derives from these multivariate lesion segmentations. The novelty of this explanatory framework is that it is trained from end to end, with image supervision only, just like black-box AI algorithms: the concepts of lesions and lesion categories emerge by themselves. For improved lesion localization, foreground/background separation is trained through self-supervision, in such a way that occluding foreground pixels transforms the input image into a healthy-looking image. The advantage of such an architecture is that automatic diagnoses can be explained simply by an image and/or a few sentences. ExplAIn is evaluated at the image level and at the pixel level on various CFP image datasets. We expect this new framework, which jointly offers high classification performance and explainability, to facilitate AI deployment.}
}